05/06 07:49:44PM parser.py:28 [INFO] 
05/06 07:49:44PM parser.py:29 [INFO] Parameters:
05/06 07:49:44PM parser.py:31 [INFO] DAG=Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('skip_connect', 6)]], DAG1_concat=[6, 7], DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)]], DAG2_concat=[6, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[6, 7])
05/06 07:49:44PM parser.py:31 [INFO] AMP_OPT_LEVEL=O0
05/06 07:49:44PM parser.py:31 [INFO] AMP_SYNC_BN=True
05/06 07:49:44PM parser.py:31 [INFO] AUX_WEIGHT=0.4
05/06 07:49:44PM parser.py:31 [INFO] BATCH_SIZE=128
05/06 07:49:44PM parser.py:31 [INFO] CUTOUT_LENGTH=16
05/06 07:49:44PM parser.py:31 [INFO] DATA_PATH=../data/
05/06 07:49:44PM parser.py:31 [INFO] DATASET=cifar10
05/06 07:49:44PM parser.py:31 [INFO] DIST=False
05/06 07:49:44PM parser.py:31 [INFO] DROP_PATH_PROB=0.2
05/06 07:49:44PM parser.py:31 [INFO] EPOCHS=2
05/06 07:49:44PM parser.py:31 [INFO] EXCLUDE_BIAS_AND_BN=True
05/06 07:49:44PM parser.py:31 [INFO] GENOTYPE=Genotype(normal=[[('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('skip_connect', 0), ('sep_conv_3x3', 1)], [('skip_connect', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)]], normal_concat=[2, 3, 4, 5], reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce_concat=[2, 3, 4, 5])
05/06 07:49:44PM parser.py:31 [INFO] GPUS=[0]
05/06 07:49:44PM parser.py:31 [INFO] GRAD_CLIP=5.0
05/06 07:49:44PM parser.py:31 [INFO] INIT_CHANNELS=36
05/06 07:49:44PM parser.py:31 [INFO] LAYERS=20
05/06 07:49:44PM parser.py:31 [INFO] LOCAL_RANK=0
05/06 07:49:44PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
05/06 07:49:44PM parser.py:31 [INFO] LR=0.025
05/06 07:49:44PM parser.py:31 [INFO] MOMENTUM=0.9
05/06 07:49:44PM parser.py:31 [INFO] NAME=augment_test2
05/06 07:49:44PM parser.py:31 [INFO] PATH=results/augment_Stage/cifar/augment_test2
05/06 07:49:44PM parser.py:31 [INFO] PRINT_FREQ=50
05/06 07:49:44PM parser.py:31 [INFO] RESUME_PATH=None
05/06 07:49:44PM parser.py:31 [INFO] SEED=0
05/06 07:49:44PM parser.py:31 [INFO] TRAIN_PORTION=0.5
05/06 07:49:44PM parser.py:31 [INFO] WEIGHT_DECAY=0.0003
05/06 07:49:44PM parser.py:31 [INFO] WORKERS=4
05/06 07:49:44PM parser.py:32 [INFO] 
05/06 07:49:44PM augmentStage_main.py:41 [INFO] Logger is set - training start
05/06 07:49:46PM augmentStage_main.py:131 [INFO] Epoch 0 LR 0.0125
05/06 07:49:47PM augmentStage_main.py:156 [INFO] Train: [  1/2] Step 000/195 Loss 3.300 Prec@(1,5) (7.8%, 57.8%)
05/06 07:50:02PM augmentStage_main.py:156 [INFO] Train: [  1/2] Step 050/195 Loss 3.193 Prec@(1,5) (14.2%, 60.0%)
05/06 07:50:16PM augmentStage_main.py:156 [INFO] Train: [  1/2] Step 100/195 Loss 3.093 Prec@(1,5) (16.6%, 65.8%)
05/06 07:50:31PM augmentStage_main.py:156 [INFO] Train: [  1/2] Step 150/195 Loss 2.967 Prec@(1,5) (20.0%, 71.0%)
05/06 07:50:44PM augmentStage_main.py:156 [INFO] Train: [  1/2] Step 195/195 Loss 2.862 Prec@(1,5) (22.8%, 74.3%)
05/06 07:50:44PM augmentStage_main.py:167 [INFO] Train: [  1/2] Final Prec@1 22.7800%
05/06 07:50:45PM augmentStage_main.py:193 [INFO] Valid: [  1/2] Step 000/039 Loss 1.699 Prec@(1,5) (36.7%, 88.3%)
05/06 07:50:48PM augmentStage_main.py:193 [INFO] Valid: [  1/2] Step 039/039 Loss 1.841 Prec@(1,5) (31.7%, 85.5%)
05/06 07:50:49PM augmentStage_main.py:203 [INFO] Valid: [  1/2] Final Prec@1 31.7000%
05/06 07:50:49PM augmentStage_main.py:116 [INFO] until now best Prec@1 = 31.7000%
05/06 07:50:49午後 augmentStage_main.py:131 [INFO] Epoch 1 LR 0.0
05/06 07:50:49午後 augmentStage_main.py:156 [INFO] Train: [  2/2] Step 000/195 Loss 2.726 Prec@(1,5) (27.3%, 82.0%)
05/06 07:51:05午後 augmentStage_main.py:156 [INFO] Train: [  2/2] Step 050/195 Loss 2.782 Prec@(1,5) (25.8%, 80.3%)
05/06 07:51:21午後 augmentStage_main.py:156 [INFO] Train: [  2/2] Step 100/195 Loss 2.781 Prec@(1,5) (25.9%, 80.3%)
05/06 07:51:36午後 augmentStage_main.py:156 [INFO] Train: [  2/2] Step 150/195 Loss 2.781 Prec@(1,5) (26.4%, 80.2%)
05/06 07:51:50午後 augmentStage_main.py:156 [INFO] Train: [  2/2] Step 195/195 Loss 2.777 Prec@(1,5) (26.6%, 80.4%)
05/06 07:51:50午後 augmentStage_main.py:167 [INFO] Train: [  2/2] Final Prec@1 26.5960%
05/06 07:51:50午後 augmentStage_main.py:193 [INFO] Valid: [  2/2] Step 000/039 Loss 1.598 Prec@(1,5) (39.8%, 87.5%)
05/06 07:51:54午後 augmentStage_main.py:193 [INFO] Valid: [  2/2] Step 039/039 Loss 1.736 Prec@(1,5) (33.7%, 86.8%)
05/06 07:51:54午後 augmentStage_main.py:203 [INFO] Valid: [  2/2] Final Prec@1 33.6800%
05/06 07:51:54午後 augmentStage_main.py:116 [INFO] until now best Prec@1 = 33.6800%
05/06 07:51:55午後 augmentStage_main.py:121 [INFO] Final best Prec@1 = 33.6800%
