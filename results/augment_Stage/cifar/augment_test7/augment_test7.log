05/06 09:04:22PM parser.py:28 [INFO] 
05/06 09:04:22PM parser.py:29 [INFO] Parameters:
05/06 09:04:22PM parser.py:31 [INFO] DAG=Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 4)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('skip_connect', 6)]], DAG1_concat=[6, 7], DAG2=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('avg_pool_3x3', 4), ('skip_connect', 6)]], DAG2_concat=[6, 7], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 3), ('skip_connect', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)]], DAG3_concat=[6, 7])
05/06 09:04:22PM parser.py:31 [INFO] AMP_OPT_LEVEL=O0
05/06 09:04:22PM parser.py:31 [INFO] AMP_SYNC_BN=True
05/06 09:04:22PM parser.py:31 [INFO] AUX_WEIGHT=0.4
05/06 09:04:22PM parser.py:31 [INFO] BATCH_SIZE=128
05/06 09:04:22PM parser.py:31 [INFO] CUTOUT_LENGTH=16
05/06 09:04:22PM parser.py:31 [INFO] DATA_PATH=../data/
05/06 09:04:22PM parser.py:31 [INFO] DATASET=cifar10
05/06 09:04:22PM parser.py:31 [INFO] DIST=False
05/06 09:04:22PM parser.py:31 [INFO] DROP_PATH_PROB=0.2
05/06 09:04:22PM parser.py:31 [INFO] EPOCHS=3
05/06 09:04:22PM parser.py:31 [INFO] EXCLUDE_BIAS_AND_BN=True
05/06 09:04:22PM parser.py:31 [INFO] GENOTYPE=Genotype(normal=[[('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('skip_connect', 0), ('sep_conv_3x3', 1)], [('skip_connect', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)]], normal_concat=[2, 3, 4, 5], reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 2), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce_concat=[2, 3, 4, 5])
05/06 09:04:22PM parser.py:31 [INFO] GPUS=[0]
05/06 09:04:22PM parser.py:31 [INFO] GRAD_CLIP=5.0
05/06 09:04:22PM parser.py:31 [INFO] INIT_CHANNELS=36
05/06 09:04:22PM parser.py:31 [INFO] LAYERS=20
05/06 09:04:22PM parser.py:31 [INFO] LOCAL_RANK=0
05/06 09:04:22PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
05/06 09:04:22PM parser.py:31 [INFO] LR=0.025
05/06 09:04:22PM parser.py:31 [INFO] MOMENTUM=0.9
05/06 09:04:22PM parser.py:31 [INFO] NAME=augment_test7
05/06 09:04:22PM parser.py:31 [INFO] PATH=results/augment_Stage/cifar/augment_test7
05/06 09:04:22PM parser.py:31 [INFO] PRINT_FREQ=50
05/06 09:04:22PM parser.py:31 [INFO] RESUME_PATH=None
05/06 09:04:22PM parser.py:31 [INFO] SEED=0
05/06 09:04:22PM parser.py:31 [INFO] TRAIN_PORTION=0.5
05/06 09:04:22PM parser.py:31 [INFO] WEIGHT_DECAY=0.0003
05/06 09:04:22PM parser.py:31 [INFO] WORKERS=4
05/06 09:04:22PM parser.py:32 [INFO] 
05/06 09:04:22PM augmentStage_main.py:41 [INFO] Logger is set - training start
05/06 09:04:23PM augmentStage_main.py:133 [INFO] Epoch 0 LR 0.018750000000000003
05/06 09:04:25PM augmentStage_main.py:158 [INFO] Train: [  1/3] Step 000/195 Loss 3.300 Prec@(1,5) (7.8%, 57.8%)
05/06 09:04:55PM augmentStage_main.py:158 [INFO] Train: [  1/3] Step 050/195 Loss 3.201 Prec@(1,5) (14.4%, 60.3%)
05/06 09:05:25PM augmentStage_main.py:158 [INFO] Train: [  1/3] Step 100/195 Loss 3.089 Prec@(1,5) (17.5%, 67.2%)
05/06 09:05:55PM augmentStage_main.py:158 [INFO] Train: [  1/3] Step 150/195 Loss 2.941 Prec@(1,5) (21.3%, 72.7%)
05/06 09:06:24PM augmentStage_main.py:158 [INFO] Train: [  1/3] Step 195/195 Loss 2.836 Prec@(1,5) (24.1%, 75.7%)
05/06 09:06:24PM augmentStage_main.py:169 [INFO] Train: [  1/3] Final Prec@1 24.1040%
05/06 09:06:24PM augmentStage_main.py:195 [INFO] Valid: [  1/3] Step 000/195 Loss 1.718 Prec@(1,5) (29.7%, 92.2%)
05/06 09:06:34PM augmentStage_main.py:195 [INFO] Valid: [  1/3] Step 050/195 Loss 1.905 Prec@(1,5) (32.3%, 87.3%)
05/06 09:06:44PM augmentStage_main.py:195 [INFO] Valid: [  1/3] Step 100/195 Loss 1.894 Prec@(1,5) (33.0%, 87.0%)
05/06 09:06:53PM augmentStage_main.py:195 [INFO] Valid: [  1/3] Step 150/195 Loss 1.897 Prec@(1,5) (33.2%, 86.6%)
05/06 09:07:02PM augmentStage_main.py:195 [INFO] Valid: [  1/3] Step 195/195 Loss 1.890 Prec@(1,5) (33.3%, 86.8%)
05/06 09:07:02PM augmentStage_main.py:205 [INFO] Valid: [  1/3] Final Prec@1 33.2680%
05/06 09:07:02PM augmentStage_main.py:118 [INFO] until now best Prec@1 = 33.2680%
05/06 09:07:02午後 augmentStage_main.py:133 [INFO] Epoch 1 LR 0.006250000000000004
05/06 09:07:03午後 augmentStage_main.py:158 [INFO] Train: [  2/3] Step 000/195 Loss 2.782 Prec@(1,5) (30.5%, 82.8%)
05/06 09:07:35午後 augmentStage_main.py:158 [INFO] Train: [  2/3] Step 050/195 Loss 2.458 Prec@(1,5) (35.4%, 86.5%)
05/06 09:08:07午後 augmentStage_main.py:158 [INFO] Train: [  2/3] Step 100/195 Loss 2.400 Prec@(1,5) (36.7%, 87.4%)
05/06 09:08:40午後 augmentStage_main.py:158 [INFO] Train: [  2/3] Step 150/195 Loss 2.368 Prec@(1,5) (37.6%, 87.9%)
05/06 09:09:07午後 augmentStage_main.py:158 [INFO] Train: [  2/3] Step 195/195 Loss 2.348 Prec@(1,5) (38.0%, 88.2%)
05/06 09:09:07午後 augmentStage_main.py:169 [INFO] Train: [  2/3] Final Prec@1 38.0280%
05/06 09:09:07午後 augmentStage_main.py:195 [INFO] Valid: [  2/3] Step 000/195 Loss 1.525 Prec@(1,5) (44.5%, 93.0%)
05/06 09:09:16午後 augmentStage_main.py:195 [INFO] Valid: [  2/3] Step 050/195 Loss 1.558 Prec@(1,5) (41.9%, 90.9%)
05/06 09:09:25午後 augmentStage_main.py:195 [INFO] Valid: [  2/3] Step 100/195 Loss 1.565 Prec@(1,5) (41.7%, 90.7%)
05/06 09:09:34午後 augmentStage_main.py:195 [INFO] Valid: [  2/3] Step 150/195 Loss 1.571 Prec@(1,5) (41.5%, 90.4%)
05/06 09:09:41午後 augmentStage_main.py:195 [INFO] Valid: [  2/3] Step 195/195 Loss 1.564 Prec@(1,5) (41.9%, 90.6%)
05/06 09:09:41午後 augmentStage_main.py:205 [INFO] Valid: [  2/3] Final Prec@1 41.8600%
05/06 09:09:41午後 augmentStage_main.py:118 [INFO] until now best Prec@1 = 41.8600%
05/06 09:09:42午後 augmentStage_main.py:133 [INFO] Epoch 2 LR 0.0
05/06 09:09:42午後 augmentStage_main.py:158 [INFO] Train: [  3/3] Step 000/195 Loss 2.131 Prec@(1,5) (45.3%, 92.2%)
05/06 09:10:14午後 augmentStage_main.py:158 [INFO] Train: [  3/3] Step 050/195 Loss 2.312 Prec@(1,5) (39.1%, 89.1%)
05/06 09:10:47午後 augmentStage_main.py:158 [INFO] Train: [  3/3] Step 100/195 Loss 2.304 Prec@(1,5) (39.4%, 89.2%)
05/06 09:11:19午後 augmentStage_main.py:158 [INFO] Train: [  3/3] Step 150/195 Loss 2.311 Prec@(1,5) (39.2%, 89.0%)
05/06 09:11:47午後 augmentStage_main.py:158 [INFO] Train: [  3/3] Step 195/195 Loss 2.321 Prec@(1,5) (38.7%, 88.8%)
05/06 09:11:47午後 augmentStage_main.py:169 [INFO] Train: [  3/3] Final Prec@1 38.6960%
05/06 09:11:48午後 augmentStage_main.py:195 [INFO] Valid: [  3/3] Step 000/195 Loss 1.525 Prec@(1,5) (41.4%, 91.4%)
05/06 09:11:57午後 augmentStage_main.py:195 [INFO] Valid: [  3/3] Step 050/195 Loss 1.602 Prec@(1,5) (39.7%, 89.8%)
05/06 09:12:07午後 augmentStage_main.py:195 [INFO] Valid: [  3/3] Step 100/195 Loss 1.594 Prec@(1,5) (40.1%, 89.9%)
05/06 09:12:17午後 augmentStage_main.py:195 [INFO] Valid: [  3/3] Step 150/195 Loss 1.580 Prec@(1,5) (40.7%, 90.3%)
05/06 09:12:25午後 augmentStage_main.py:195 [INFO] Valid: [  3/3] Step 195/195 Loss 1.577 Prec@(1,5) (40.9%, 90.4%)
05/06 09:12:25午後 augmentStage_main.py:205 [INFO] Valid: [  3/3] Final Prec@1 40.9080%
05/06 09:12:25午後 augmentStage_main.py:118 [INFO] until now best Prec@1 = 41.8600%
05/06 09:12:25午後 augmentStage_main.py:123 [INFO] Final best Prec@1 = 41.8600%
